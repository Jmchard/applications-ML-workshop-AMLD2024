{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cfcc082-af24-4085-a5db-81e5d5d0b0f1",
   "metadata": {},
   "source": [
    "# Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f695f98-e0c8-4e1b-8c48-98502a852952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup Google Colab by running this cell only once (ignore this if run locally) {display-mode: \"form\"}\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Clone GitHub repository\n",
    "    !git clone https://github.com/epfl-exts/amld24-applications-ML-workshop.git\n",
    "        \n",
    "    # Copy files required to run the code\n",
    "    !cp -r \"amld24-applications-ML-workshop/timeseries_regression_case_study/data\" \"amld24-applications-ML-workshop/timeseries_regression_case_study/tools.py\" .\n",
    "    \n",
    "    # Install packages via pip\n",
    "    !pip install -r \"amld24-applications-ML-workshop/colab-requirements.txt\"\n",
    "    \n",
    "    # Restart Runtime\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d8a08-5633-4cdb-a32c-fac786bd0074",
   "metadata": {},
   "source": [
    "# Time series Forecasting\n",
    "\n",
    "__Notebook overview__:\n",
    "\n",
    "- Task description\n",
    "- First look at Data\n",
    "- Explore the data\n",
    "- Correlation analysis\n",
    "- Split data\n",
    "- Training\n",
    "- Prediction and evaluation\n",
    "\n",
    "## Task description\n",
    " \n",
    "We want to develop a model to forecast the one hour ahead electricity load based on the hourly electricity load and temperature data.\n",
    "\n",
    "## First look at Data\n",
    "\n",
    "We use the data from the [Global Energy Forecasting Competition](https://en.wikipedia.org/wiki/Global_Energy_Forecasting_Competition). We focus on the data for the year 2014 which contains 8'760 observations. The dataset has been downloaded for you and is available in the *data* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534870d-9c85-4339-9a8a-8e54424013ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load settings and functions\n",
    "%run tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5586c1d-4653-4af5-9853-cbdf5a02c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6dd45b-0c4c-47af-b266-f3053a1abf81",
   "metadata": {},
   "source": [
    "Let's have a close look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73a4f8-1499-4499-8498-ede30dfb6ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367131e1-da41-4fc7-8ed0-5b537f7df46e",
   "metadata": {},
   "source": [
    "Let's have a look at a few rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d446c-c0c4-4896-bfbf-801db47b4836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679e56b-9522-4542-af30-b905ce8847f6",
   "metadata": {},
   "source": [
    "##Â Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f5c142-fa71-467b-8aca-39bfad80b554",
   "metadata": {},
   "source": [
    "Now, let's visualise the electric loads and the temperature. Note that due to the centric role of the time dimension in time series data one should explore the dynamics of the features and the target over time (__trends and cycles__). Also, one should check how the target is correlated with its own values in the past (__temporal dependencies__). Finally, one should be mindful of the changes in the distribution of the data over time (__stationarity__). Since our data is stationary, we only check the trends, cycles and temporal dependencies in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef31afbb-71a0-429f-93c4-fc0e832f2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32083c0e-7c4a-4a67-a65f-629fcc355e67",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Observations\n",
    "\n",
    "__Distributions__: The two plots in the 1st row show bimodal distributions meaning that data are centered around two values (e.g. ~0 and ~18 for the temperature). <br>\n",
    "\n",
    "__Common characteristic of the electric load and temperature__:  The two plots in the 2nd and 3rd rows show that, both electric load and temperature time-series show seasonal trends meaning that there are regular repetitions of patterns over time. Therefore, in general, the time could provide a basis for our expectation of the electric load. For instance, the plot in the second row shows that the load is higher at the beginning, middle, and end of the year when the weather is either too cold or too hot.<br>\n",
    "\n",
    "__Daily and hourly patterns__: The plots in the 4th row show that the electric load is higher during the weekdays (compared to the weekends) and during the daytime (compared to the nights). Therefore, it makes sense to keep these features and use them in our models. <br>\n",
    "\n",
    "__Monthly patterns__: The heatmap in the last row shows that the month is not much relevant from 1am to 5am. However, since 6am demand for the electricity depends on the month. So, the month matters for the loads during the day. We conclude that the interactions of time features (hour and month) could also matter for the electric load. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9e65db-fcaa-44f7-9943-65859e927d56",
   "metadata": {},
   "source": [
    "## Correlation analysis\n",
    "Here, we create two features that can play a big role in forecasting the load. One simple conjecture is that the past values of the load and temperature can predict the load. Our data has an hourly frequency and our objective is to predict the load one hour ahead. Therefore, we create lags of the load and temperature, and then check the correlations and auto-correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db0307-4426-48fa-afe3-6e0484d5683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(df, n_lags=1) # n_lag takes values between 1 and 24 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c0a55-a440-4f73-8058-61255ab5bbb6",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Observations\n",
    "\n",
    "__The auto-correlation plot:__ It shows that the load is auto-correlated with many lagged loads. But the 1st lag leads to the highest auto-correlation for the electric load. So, the load from previous hour can best represent the current load. <br>\n",
    "\n",
    "__Linear relationship:__ In the second row, we observe a linear relationship between the current load the load 1 hours ago. But the current load is not linearly related to the temperature 1 hours ago, according to the second plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8382374d-3fc2-4e55-9f6f-1b9eff6709ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "Try changing `n_lags` in the correlation analysis and see the outcome.<br>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bff4da-cd7a-4d75-9e9e-b2ea5e7b57eb",
   "metadata": {},
   "source": [
    "## Split data\n",
    "Let's split the data set. We use the last month of the data, i.e. December, for testing and the rest of the data, that is January to November, for training and validations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e13833-4dc9-4de4-bb8f-ff956905003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test splitting\n",
    "train, test = sample_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a068dbb-9c72-4247-bab9-54190b606bb7",
   "metadata": {},
   "source": [
    "## Training\n",
    "Based on the correlation analysis, we decide to use the 1st lags of the load and temperature as features in our model. We also have the insight that these features are related to the target in both linear and non-linear ways. Therefore, we build linear and non-linear models to predict the one-hour-ahead electric load. \n",
    "\n",
    "We choose either of the ridge regression or random forest as the machine learning model. Note that each model requires an appropriate preprocessing of the features. For instance, the ridge regression requires the continuous features to be scaled, and both models require one-hot encoding of the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c0107-e592-4894-88f4-a650525a84fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a ridge regression or a random forest model on the train data\n",
    "model = train_model(train, select_model='regression') #Â select_model = 'regression' or 'randomforest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95354d53-23f7-402f-89a7-82bae68b5d8a",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Observations\n",
    "\n",
    "__Ridge regression__: The error measured by MAE is not constant. It increases by $\\alpha$. Larger values of $\\alpha$ don't allow the model to fully benefit from the features. So the performance become progressively worse.<br>\n",
    "\n",
    "__Training vs validation errors__: The validation error is higher than the training error, indicating that the model slightly overfits. One possible explanation for this issue is in the structure and size of the data set. More precisely, since the validation set (e.g. July) always comes ahead of the train set (e.g. January to June), the model cannot generalize to the attributes that are specific to July. A solution for this issue is to increase the size of the train set, e.g. collecting more data and training the model on a full year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70cb781-c140-46d9-a9aa-1557d9e560cc",
   "metadata": {},
   "source": [
    "## Prediction and evaluation\n",
    "The first step here is to define our evaluation metric and baseline. We choose the **mean absolute error (MAE) as the metric** and **the median as the baseline**. Note that you can even consider the loads from the previous hour as a prediction for the current load without any modeling. In other words, **the lagged loads can act as a (smart) baseline before building any model**. Below, you can see how the performance of such a baseline can be compared with the statistical baseline and our models.\n",
    "\n",
    "Let's evaluate the performance of the model we previously chose by `select_model` and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd861f-8a7b-4861-b68b-52128bf9b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the actual and predicted values for the last n_days of test set\n",
    "# n_days takes values between 1 and 31\n",
    "evaluate_model(model, train, test, n_days=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444defee-daeb-4ff5-9f3b-ca00bde71c72",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Observations\n",
    "\n",
    "The first plot show that the model doesn't remarkably outperform the smart baseline as it does to the first baseline i.e. median. This is a common situation for time series data with high auto-correlation which may put machine learning models in difficult position to be justified and deployed. \n",
    "\n",
    "In the second plot we show the predicted load with the model of your choice in `select_model` along with the observed loads in the test set for the period of `n_days`. The plot also shows the two baselines.\n",
    "\n",
    "Note that our objective was to build models that can predict the electric loads one hour ahead. But you can develop a setup where you can change the prediction horizon to be more than only one hour. Deciding about the prediction horizon depends on the domain, the problem that is intended to be solved, and the added value of the machine learning project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0b733d-0c9d-44ec-9178-5736d1e0314c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Letâ€™s compare the ridge regression and the random forest model. <br>\n",
    "    \n",
    "1. Go back to the subsection **Training** and change the `select_model`-parameter inside the `train_model`-function to `'randomforest'` (Careful you need the quotation marks).<br>\n",
    "    \n",
    "2. Run `evaluate_model` again and compare the results.\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:amld]",
   "language": "python",
   "name": "conda-env-amld-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
