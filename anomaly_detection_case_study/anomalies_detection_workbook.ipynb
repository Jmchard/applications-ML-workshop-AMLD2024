{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection - the data\n",
    "## Load settings and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3>Important</h3>\n",
    "\n",
    "<p>When training the model we will only pass it the features of the samples. The model will never see the class labels, and hence can not gain any feedback from comparing them against its own 'decisions'.<br>\n",
    "Thus anomaly detection is an <b>unsupervised</b> machine learning approach.</p>\n",
    "    \n",
    "<p>However, here we will use the class labels to gain further insight by analysing and visualising the data and later for evaluating our model in some more detail.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the training data and visualise 1000 samples\n",
    "\n",
    "1) We look at the distribution of different attack types in our training data.\n",
    "\n",
    "2) We use a TSNE-plot to explore part of our training data.  \n",
    "The TSNE-plot reduces our 51 features to 2 dimensions by trying to represent local structures faithfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_and_visualise_training_data(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h2>Questions - Part 1</h2>\n",
    "    \n",
    "The purpose of these questions is to create some expectations of the performance of our model and the problems it might encounter.\n",
    "\n",
    "Note: <i>These questions only make sense for training data that has been contaminated</i>.\n",
    "    \n",
    "What do you observe about <br>\n",
    "<ul>\n",
    "<li> the <b>frequency of the different malware types</b> in our data set? </li>\n",
    "<li> the <b>distribution of the different malware types</b> in the TSNE plot? </li>\n",
    "<li> the <b>distribution of the normal samples</b> in the TSNE plot? </li>\n",
    "</ul>\n",
    "\n",
    "<b>Which types of malware</b> do you expect to be <b>easy to find</b>, and which ones would be <b>harder to detect</b>?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My observations:\n",
    "\n",
    "-  \n",
    "-  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection - the model\n",
    "## Training our model\n",
    "\n",
    "The **expected_contamination** is the portion of anomalies (attacks) that we expect in the real-life test set. This value is independent of the *portion of attacks* we chose to place in the training data.\n",
    "\n",
    "**PCA (Principal Component Analysis)** transforms our data by trying to identify the directions (= combinations of features) in the data in which the data varies most. This might help the Isolation Forest algorithm to isolate anomalies faster, or it might not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, dataset = build_anomaly_detector(\n",
    "    dataset,\n",
    "    expected_contamination=0.1,      # value between 0 and 0.5\n",
    "    with_PCA = False)                # True / False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the performance\n",
    "\n",
    "1) We take at look at the scores assigned by the **decision function** to our different samples. Samples with negative scores are marked as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h2>Questions - Part 2</h2>\n",
    "\n",
    "<p>Let's take a look at the results above. First take a look at everything, then try to answer the following questions:</p>\n",
    "\n",
    "<ol>\n",
    "<li>  In the first plot how many blue samples are found on the left hand side?</li>\n",
    "<li>  In the first plot how many orange samples are found on the right hand side?</li>\n",
    "<li>  Which of these two mispredictions are worse for us?</li>\n",
    "</ol>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My observations:\n",
    "\n",
    "-  \n",
    "-  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a more detailed look at our performance\n",
    "\n",
    "1) We look at the performance of our predictions at the level of individual attack types.\n",
    "\n",
    "2) We locate the misclassified samples (triangles, colour gives true label) inside our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_evaluation(dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h2>Questions - Part 3</h2>\n",
    "\n",
    "Let's compare our expectations build from Part 1 with the actual performance. \n",
    "\n",
    "<ol>\n",
    "<li>  For which types of malware did our model perform well, and for which did it do poorly?</li>\n",
    "<li>  Does this match the observations and expectations we made in Part 1?</li>\n",
    "</ol>   \n",
    "<p>Dark blue triangles indicate false alarms, i.e. normal behaviour that was predicted as malware. <br>\n",
    "The other triangles indicate malware that was not detected.</p>\n",
    "\n",
    "<ol start=\"3\">\n",
    "<li>  What do you observe about the location of the false alarms?</li>\n",
    "<li>  What do you observe about the location of undetected malware?</li>\n",
    "<li>  Does this match the observations and expectations we made in Part 1?</li>\n",
    "</ol>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My observations:\n",
    "\n",
    "-  \n",
    "-  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Task 1</h3>\n",
    "\n",
    "Let's vary the `expected_contamination` parameter which is used by the model to make decisions. <br>     You only need to run cells in section 2 \"Anomaly detection - the model\" <br>    \n",
    "What do you observe about distribution of the outlier scores and the position of the decision boundary?<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Task 2</h3>\n",
    "\n",
    "You need to rerun the entire notebook here. <br>\n",
    "1. Vary the size of your training data.<br> \n",
    "2. Vary the portion of attacks in your training data.<br>\n",
    "3. In particular let's see how the model performs when we only use totally clean training data without any anomalies.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Task 3</h3>\n",
    "    \n",
    "Let's see whether using PCA before training our model helps. <br> \n",
    "You only need to run cells in  section 2 \"Anomaly detection - the model\"<br>\n",
    "    \n",
    "Set `with_PCA = True` inside the `build_anomaly_detector`. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adsml_M1] *",
   "language": "python",
   "name": "conda-env-adsml_M1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
